{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация комментариев\n",
    "\n",
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "**Задача:**   \n",
    "Построить модель для классифиции комментариев на позитивные и негативные со значением метрики качества *F1* не меньше 0.75\n",
    "\n",
    "**Объект исследования:**   \n",
    "Набор данных с разметкой о токсичности правок. Столбец text в нём содержит текст комментария, а toxic — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Импорт-библиотек\" data-toc-modified-id=\"Импорт-библиотек-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Импорт библиотек</a></span></li><li><span><a href=\"#Загрузка-и-знакомство-с-данными\" data-toc-modified-id=\"Загрузка-и-знакомство-с-данными-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Загрузка и знакомство с данными</a></span><ul class=\"toc-item\"><li><span><a href=\"#сокращение-выборки\" data-toc-modified-id=\"сокращение-выборки-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>сокращение выборки</a></span></li></ul></li><li><span><a href=\"#Предобработка-текста\" data-toc-modified-id=\"Предобработка-текста-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Предобработка текста</a></span></li><li><span><a href=\"#Деление-на-выборки\" data-toc-modified-id=\"Деление-на-выборки-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Деление на выборки</a></span></li><li><span><a href=\"#Векторное-представление\" data-toc-modified-id=\"Векторное-представление-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Векторное представление</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#LinearSVC\" data-toc-modified-id=\"LinearSVC-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>LinearSVC</a></span></li><li><span><a href=\"#SGDClassifier\" data-toc-modified-id=\"SGDClassifier-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>SGDClassifier</a></span><ul class=\"toc-item\"><li><span><a href=\"#Градиентный-бустинг-CatBoost\" data-toc-modified-id=\"Градиентный-бустинг-CatBoost-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Градиентный бустинг CatBoost</a></span></li></ul></li><li><span><a href=\"#Тестирование-модели\" data-toc-modified-id=\"Тестирование-модели-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Тестирование модели</a></span></li></ul></li><li><span><a href=\"#Итоги\" data-toc-modified-id=\"Итоги-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Итоги</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка\n",
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # установка библиотеки catboost\n",
    "# !pip install catboost\n",
    "# conda install spacy\n",
    "# !spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/thetonytime/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/thetonytime/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/thetonytime/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/thetonytime/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# импорт необходимых библиотек\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# отлеживание прогресса\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas() # для работы progress_apply в пандас\n",
    "\n",
    "# токенизация\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# лемматизация\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import spacy\n",
    "\n",
    "# словарь стоп-слов\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# векторизация текста\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# деление на выборки\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# метрика качества\n",
    "from sklearn.metrics import f1_score, make_scorer, accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "\n",
    "# подбор гипрепараметров\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_validate, StratifiedKFold\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv \n",
    "from sklearn.model_selection import HalvingRandomSearchCV, HalvingGridSearchCV\n",
    "\n",
    "#   pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# линейные модели\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# модель градиентный бустинг из библиотеки catboost\n",
    "import catboost as cb\n",
    "\n",
    "# создание собственного трансформера из функции для пайплайн\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# создание константной модели\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# скрыть предупреждения\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим 3 знака после запятой для float при отображении табли\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим переменную с начальным состоянием генератора случайности для использования в моделях и рэндомсёрче\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка и знакомство с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вывод полного текста\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "\n",
    "# откроем файл с историчекими данными\n",
    "# возможные пути расположения файла\n",
    "server_path = '/datasets/toxic_comments.csv'  \n",
    "local_path = 'toxic_comments.csv'\n",
    "colab_path = '/content/toxic_comments.csv'\n",
    "\n",
    "if os.path.exists(server_path):\n",
    "    df_original = pd.read_csv(server_path, index_col=[0]) # первый столбец сделали индексом\n",
    "elif os.path.exists(local_path):\n",
    "    df_original = pd.read_csv(local_path, index_col=[0])\n",
    "elif os.path.exists(colab_path):\n",
    "    df_original = pd.read_csv(colab_path, index_col=[0])\n",
    "else:\n",
    "    'Неправильно указан путь к файлу'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They wer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, Januar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>\":::::And for the second time of asking, when your view completely contradicts the coverage in r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is a horrible thing you put on my talk page.  128.61....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>And it looks like it was actually you who put on the speedy to have the first version deleted no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand.  I came here and my idea was bad right away.  Wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       text  \\\n",
       "0       Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They wer...   \n",
       "1       D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, Januar...   \n",
       "2       Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relev...   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics...   \n",
       "4                                       You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "...                                                                                                     ...   \n",
       "159446  \":::::And for the second time of asking, when your view completely contradicts the coverage in r...   \n",
       "159447  You should be ashamed of yourself \\n\\nThat is a horrible thing you put on my talk page.  128.61....   \n",
       "159448                  Spitzer \\n\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.   \n",
       "159449  And it looks like it was actually you who put on the speedy to have the first version deleted no...   \n",
       "159450  \"\\nAnd ... I really don't think you understand.  I came here and my idea was bad right away.  Wh...   \n",
       "\n",
       "        toxic  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "159446      0  \n",
       "159447      0  \n",
       "159448      0  \n",
       "159449      0  \n",
       "159450      0  \n",
       "\n",
       "[159292 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# запишем датафрейм для работы, сохранив исходный, и посмотрим на содержимое\n",
    "df = df_original.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В предоставленном датафрейме 159 292 объектов и 2 признака, включая целевой:\n",
    "- `text` - текст комментария на английском языке\n",
    "- `toxic` — целевой признак - токсичность комментария, где:\n",
    "    - `1` - токсичный\n",
    "    - `0` - нетоксичный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# посмотрим пропуски и типы данных\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Количество дубликатов: 0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверим на явные дубликаты\n",
    "f'Количество дубликатов: {df.duplicated().sum()}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дубликатов и пропусков нет. Типы данных подходящие.\n",
    "\n",
    "Посмотрим на распределение целевого признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Количество токсичных комментариев: 16186, доля 10.16%'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Количество токсичных комментариев: {df[\"toxic\"].sum()}, доля {df[\"toxic\"].mean() * 100 :.2f}%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеем дисбаланс классов - токсичных комментариев, которые нам нужно выявлять, всего 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "#### сокращение выборки\n",
    "Сократим выборку для ускорения вычислительных операций (практически найдено, что 10% данных достаточно для достижения удовлетворительного качества модели)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15930.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          toxic\n",
       "count 15930.000\n",
       "mean      0.102\n",
       "std       0.302\n",
       "min       0.000\n",
       "25%       0.000\n",
       "50%       0.000\n",
       "75%       0.000\n",
       "max       1.000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# отделим 2% с соблюдением распределения целевого признака\n",
    "df_useless, df_useful = train_test_split(df, \n",
    "                     random_state=random_state, \n",
    "                     test_size=0.1, \n",
    "                     stratify=df['toxic'])\n",
    "# перезапишем рабочий датасет на сокращённый\n",
    "df = df_useful\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка текста\n",
    "Прежде чем перейти к векторному представлению слов и обучению проводём очистку и предобработку текста:\n",
    "- Приведение текстов к нижнему регистру\n",
    "- Очистка от символов - оставляем только буквы, текст ссылок заменяем на слово \"сайт\"\n",
    "- Токенизация - разбиение на слова\n",
    "- Лемматизация - приводение к начальной словарной форме\n",
    "- Очистка от стоп-слов и ненужных символов\n",
    "\n",
    "Для предобработки текста напишем собственные функции `clean_text` и `lemmatize_spacy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для очистки текста\n",
    "def clean_text(text):\n",
    "    # перевести текст в нижний регистр\n",
    "    text = text.lower()\n",
    "    \n",
    "    # заменим ссылки на слово \"сайт\"\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'сайт', text) # код скопировали\n",
    "    # обращение к пользователю заменяем на \"пользователь\"\n",
    "    text = re.sub('@[^\\s]+', 'пользователь', text)\n",
    "\n",
    "    # оставляем только буквы\n",
    "    text_only = re.sub(r'[^a-z]', ' ', text)\n",
    "\n",
    "    # Удаление стоп-слов\n",
    "    stop_words = set(stopwords.words('english')) # Используем стоп-слова на английском языке\n",
    "    cleaned_list = [word for word in text_only.split() if word not in stop_words]\n",
    "    \n",
    "    # Соединяем в текст \n",
    "    prepared_text = \" \".join(cleaned_list)\n",
    "    \n",
    "    return prepared_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для лемматизации столбца с текстом\n",
    "def lemmatize_spacy(text_col):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    \n",
    "    new_corpus = []\n",
    "\n",
    "    for doc in tqdm(nlp.pipe(text_col, \n",
    "                             batch_size=64, \n",
    "                             n_process=-1, \n",
    "                             disable=[\"parser\", \"ner\"]), # убрали лишние операции\n",
    "                    total=len(text_col)):\n",
    "        word_list = [tok.lemma_ for tok in doc]\n",
    "        new_corpus.append(' '.join(word_list))\n",
    "    return new_corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Очистка текста:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15930/15930 [00:04<00:00, 3266.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лемматизация текста:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15930/15930 [01:38<00:00, 162.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>prepared_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151009</th>\n",
       "      <td>\"\\n Ok, an seems pretty clear by now what editor is responsible here. Amalthea \"</td>\n",
       "      <td>0</td>\n",
       "      <td>ok seem pretty clear editor responsible amalthea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30615</th>\n",
       "      <td>Proposal for standard infobox for History of [country] templates\\n\\nHi there! You're a member of...</td>\n",
       "      <td>0</td>\n",
       "      <td>proposal standard infobox history country template hi member wikiproject history inform proposal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35343</th>\n",
       "      <td>\"\\n\\n Hi, Pompous Ass!  ;) \\n\\nI know you think you're some kind of poker authority on Wikipedia...</td>\n",
       "      <td>1</td>\n",
       "      <td>hi pompous ass know think kind poker authority wikipedia somehow perogative give imperial final ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156814</th>\n",
       "      <td>I am under attack! \\n\\nYou guys are censoring any opinion that you do not agree with! And you ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>attack guy censoring opinion agree respond proof point view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97214</th>\n",
       "      <td>Why include Peter and Emerich?==\\n\\nPeter the Hermit and Emerich's respective endeavours really ...</td>\n",
       "      <td>0</td>\n",
       "      <td>include peter emerich peter hermit emerich respective endeavour really nothing actual first crus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       text  \\\n",
       "151009                     \"\\n Ok, an seems pretty clear by now what editor is responsible here. Amalthea \"   \n",
       "30615   Proposal for standard infobox for History of [country] templates\\n\\nHi there! You're a member of...   \n",
       "35343   \"\\n\\n Hi, Pompous Ass!  ;) \\n\\nI know you think you're some kind of poker authority on Wikipedia...   \n",
       "156814  I am under attack! \\n\\nYou guys are censoring any opinion that you do not agree with! And you ha...   \n",
       "97214   Why include Peter and Emerich?==\\n\\nPeter the Hermit and Emerich's respective endeavours really ...   \n",
       "\n",
       "        toxic  \\\n",
       "151009      0   \n",
       "30615       0   \n",
       "35343       1   \n",
       "156814      0   \n",
       "97214       0   \n",
       "\n",
       "                                                                                              prepared_text  \n",
       "151009                                                     ok seem pretty clear editor responsible amalthea  \n",
       "30615   proposal standard infobox history country template hi member wikiproject history inform proposal...  \n",
       "35343   hi pompous ass know think kind poker authority wikipedia somehow perogative give imperial final ...  \n",
       "156814                                          attack guy censoring opinion agree respond proof point view  \n",
       "97214   include peter emerich peter hermit emerich respective endeavour really nothing actual first crus...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# очистка текста - применим функцию к каждому элементу столбца \n",
    "print('Очистка текста:')\n",
    "df['prepared_text'] = df['text'].progress_apply(lambda x: clean_text(x))\n",
    "# лемматизация текста - применим функцию ко всему столбцу\n",
    "print('Лемматизация текста:')\n",
    "df['prepared_text'] = lemmatize_spacy(df['prepared_text'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  второй способ лемматизации, выполняется дольше\n",
    "# # вспомогательная функция для лемматизации\n",
    "# # функция для добавления pos-тега (части речи) для работы nltk-лемматизатора \n",
    "# def get_wordnet_pos(word):\n",
    "#     tag = nltk.pos_tag([word])[0][1][0].upper() # определяет pos-тег слова, берёт из него часть речи (вторую букву)\n",
    "#     # словарь для присваивания части речи\n",
    "#     tag_dict = {\"J\": wordnet.ADJ, \n",
    "#                 \"N\": wordnet.NOUN,\n",
    "#                 \"V\": wordnet.VERB,\n",
    "#                 \"R\": wordnet.ADV}\n",
    "#     # возвращает из словаря обозначение нужной части речи по вычисленному тегу, при отсутствии тега, вернёт существительное\n",
    "#     return tag_dict.get(tag, wordnet.NOUN) \n",
    "\n",
    "# # функция для очистки текста\n",
    "# def preprocess_text(text):\n",
    "#     # перевести текст в нижний регистр\n",
    "#     text = text.lower()\n",
    "    \n",
    "#     # заменим ссылки на слово \"сайт\"\n",
    "#     #text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'сайт', text) # код скопировали\n",
    "#     # обращение к пользователю заменяем на \"пользователь\"\n",
    "#     #text = re.sub('@[^\\s]+', 'пользователь', text)\n",
    "\n",
    "#     # оставляем только буквы\n",
    "#     text_only = re.sub(r'[^a-z]', ' ', text)\n",
    "    \n",
    "#     # Токенизация текста для дальнейшей лемматизации\n",
    "#     tokenized = nltk.word_tokenize(text_only)\n",
    "    \n",
    "    \n",
    "#     # Создаем экземпляр лемматизатора\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     # Лемматизация с соответствующим pos-тегом\n",
    "#     lemm_list = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in tokenized]\n",
    "    \n",
    "   \n",
    "#     Удаление стоп-слов\n",
    "#     stop_words = set(stopwords.words('english')) # Используем стоп-слова на английском языке\n",
    "#     cleaned_list = [word for word in lemm_list if word not in stop_words]\n",
    "    \n",
    "#     # Соединяем в текст \n",
    "#     prepared_text = \" \".join(cleaned_list)\n",
    "    \n",
    "#     return prepared_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Деление на выборки\n",
    "Перед векторизацией разделим выборки, чтобы избежать утечки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# целевой признак\n",
    "y = df['toxic']\n",
    "X = df['prepared_text']\n",
    "\n",
    "# разделим датасет на обучающуи тестовую выборки 85/15, сохранив распределение целевого признака\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y,\n",
    "                                                     random_state=random_state, \n",
    "                                                     test_size=0.15, \n",
    "                                                     stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающая выборка: 13540, 0.102, \n",
      "Тестовая выборка: 2390, 0.102\n"
     ]
    }
   ],
   "source": [
    "# проверим распределение целевого признака в выборках и их размеры\n",
    "print(f\"\"\"Обучающая выборка: {y_train.shape[0]}, {y_train.mean():.3f}, \n",
    "Тестовая выборка: {y_test.shape[0]}, {y_test.mean():.3f}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление\n",
    "Подготовленный текст передадим алгоритмам, которые переведут их в векторные представления. Для этого модель обращается к составленному заранее словарю токенов. На выходе для каждого текста образуются вектор заданной длины.\n",
    "\n",
    "\n",
    "В рамках задачи попробуем подобрать наиболее эффективное векторное представление. Рассмотрим варианты:\n",
    "1. Bag of words, Bag of words с биграммами и триграммами, TF-IDF, TF-IFD c биграммами и триграммами\n",
    "\n",
    "Подберём лучший вариан обучением логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best parameters: {'vectorizer__ngram_range': (1, 1), 'vectorizer': TfidfVectorizer(), 'logreg__max_iter': 300, 'logreg__C': 9}\n",
      "Best score: 0.6887688884393028\n"
     ]
    }
   ],
   "source": [
    "# константное разбиение на фолды для кросс-валидации с соблюдением распределения целевого признака\n",
    "kf = StratifiedKFold(n_splits=5, random_state=random_state, shuffle=True)\n",
    "\n",
    "# пайплайн для векторизации TfidfVectorizer\n",
    "pipeline_vec = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('logreg', LogisticRegression(random_state=random_state))\n",
    "])\n",
    "\n",
    "# подбираем параметры для векторизации\n",
    "parameters = {\n",
    "    'vectorizer': [ TfidfVectorizer()],\n",
    "#     'vectorizer__max_df': np.linspace(0.2, 0.98),\n",
    "    'vectorizer__ngram_range':  [(1, 1), (1, 2), (1, 3)],\n",
    "    'logreg__C': ['balanced', None],\n",
    "    'logreg__C': range(1, 10),\n",
    "    'logreg__max_iter': [300]\n",
    "                }\n",
    "\n",
    "rand_search_vec = RandomizedSearchCV(pipeline_vec, parameters, cv=kf, n_iter=10, n_jobs=-1, scoring='f1', verbose=1,\n",
    "                                      random_state=random_state)\n",
    "rand_search_vec.fit(X_train, y_train)\n",
    "\n",
    "# Вывод наилучших параметров и оценки\n",
    "print(\"Best parameters:\", rand_search_vec.best_params_)\n",
    "print(\"Best score:\", rand_search_vec.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Лучше всего в комбинации с логистической регрессией отработали мешок слов и TF-IDF без биграмм. \n",
    "Для дальнейшей работы выберем векторизацию TF-IDF, так как этот алгоритм ещё учитывает важность слов в контексте всего корпуса текстов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение\n",
    "Перед нами стоит задача бинарной классификации, метод обучения с учителем. Модели будут обучаться на векторных представлениях текстов.\n",
    "Наша модель должна прогнозировать эмоциональную окраску текста — 0 («положительная») или 1 («отрицательная»). \n",
    "\n",
    "Для оценки качества и выбора лучшей модели будем использовать F1-меру. \n",
    "\n",
    "Для поиска лучшего решения протестируем:\n",
    "- LogisticRegression\n",
    "- LinearSVC\n",
    "- SGDClassifier\n",
    "- Градиентный бустинг CatBoost\n",
    "\n",
    "Для линейных моделей сделаем подбор гиперпараметров с помощью RandomizedSearchCV.  \n",
    "Гоадиентный бустинг обучим без подбора гиперпараметров на векторизированном тексте.\n",
    "\n",
    "Чтобы устранить влияние дисбаланса класса при обучении попробуем настроить гиперпараметр `class_weight`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для подбора ГП  и рассчёта метрики на кросс-валидации\n",
    "def rs_func(pipe, params):\n",
    "    # кросс-валидация будет делить на 5 частей, оцениваем по f1\n",
    "    rand_search = RandomizedSearchCV(pipe, params, cv=kf, n_jobs=-1, scoring='f1', verbose=1, \n",
    "                                      error_score=0, random_state=random_state, n_iter=10)\n",
    "    # обучаем на тренировочной выборке\n",
    "    rand_search.fit(X_train, y_train)\n",
    "    # зафиксируем лучшую модель и метрику в переменной\n",
    "    f1, model_rs = rand_search.best_score_, rand_search\n",
    "    return f1, model_rs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7309505321200525,\n",
       " {'logr__penalty': 'l2',\n",
       "  'logr__max_iter': 800,\n",
       "  'logr__class_weight': 'balanced',\n",
       "  'logr__C': 13.25})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пайплайн для логистической регрессии\n",
    "pipeline_logr = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('logr', LogisticRegression(random_state=random_state))\n",
    "])\n",
    "\n",
    "# перебор параметров для модели\n",
    "params_logr = {'logr__class_weight' : [None, 'balanced'],\n",
    "                'logr__max_iter': [200, 300, 500, 800],\n",
    "                'logr__C': np.arange(.0, 15, 0.25),\n",
    "                'logr__penalty' : ['l1', 'l2', 'elasticnet']}\n",
    "\n",
    "\n",
    "f1_logr, model_logr_rs = rs_func(pipeline_logr, params_logr)\n",
    "f1_logr, model_logr_rs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC \n",
    "Линейный метод опорных векторов с поддержкой классификации, стремится найти оптимальную разделяющую гиперплоскость между классами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7269131226680161,\n",
       " {'svc__penalty': 'l2',\n",
       "  'svc__loss': 'squared_hinge',\n",
       "  'svc__dual': False,\n",
       "  'svc__class_weight': 'balanced',\n",
       "  'svc__C': 0.25})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# пайплайн для LinearSVC\n",
    "pipeline_svc = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('svc', LinearSVC(random_state=random_state))\n",
    "])\n",
    "\n",
    "# перебор параметров для модели\n",
    "params_svc = {'svc__class_weight' : [None, 'balanced'],\n",
    "                'svc__loss': ['hinge', 'squared_hinge'],\n",
    "                'svc__C': np.arange(0.25, 3.01, 0.25),\n",
    "                'svc__penalty' : ['l1', 'l2'],\n",
    "                'svc__dual' : [True, False]}\n",
    "\n",
    "\n",
    "f1_svc, model_svc_rs = rs_func(pipeline_svc, params_svc)\n",
    "\n",
    "f1_svc, model_svc_rs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier\n",
    "Модель SGDClassifier - линейная модель классификации, обучаемая с использованием стохастического градиентного спуска. Она отличается от классического LinearSVC тем, что обновление параметров модели происходит на каждом примере обучающего набора, в отличие от обновления на каждой эпохе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thetonytime/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/thetonytime/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/thetonytime/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/thetonytime/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/thetonytime/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/thetonytime/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/thetonytime/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/thetonytime/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/thetonytime/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/thetonytime/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/thetonytime/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/thetonytime/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/thetonytime/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/thetonytime/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/thetonytime/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7185746473480423,\n",
       " {'sgd__penalty': 'l2',\n",
       "  'sgd__loss': 'hinge',\n",
       "  'sgd__class_weight': 'balanced',\n",
       "  'sgd__alpha': 0.0001})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# пайплайн для LinearSVC\n",
    "pipeline_sgd = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('sgd', SGDClassifier(random_state=random_state))\n",
    "])\n",
    "\n",
    "# перебор параметров для модели\n",
    "params_sgd = {'sgd__class_weight' : [None, 'balanced'],\n",
    "                'sgd__loss': ['hinge', 'log', 'modified_huber'],\n",
    "                'sgd__alpha': [0.0001, 0.0001, 0.001, 0.1, 1],\n",
    "                'sgd__penalty' : ['l1', 'l2', 'elasticnet']}\n",
    "\n",
    "\n",
    "f1_sgd, model_sgd_rs = rs_func(pipeline_sgd, params_sgd)\n",
    "f1_sgd, model_sgd_rs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Градиентный бустинг CatBoost\n",
    "Градиентный бустинг CatBoost обучим без подбора гиперпараметров на вектоизированной тренировочной выборке TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7370074807723123,\n",
       " {'gbc__iterations': 200, 'gbc__auto_class_weights': 'Balanced'})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# пайплайн для CatBoostClassifier\n",
    "pipeline_gbc = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('gbc', cb.CatBoostClassifier(random_state=random_state, silent=True))\n",
    "])\n",
    "\n",
    "# перебор параметров для модели\n",
    "params_gbc = {'gbc__auto_class_weights' : ['Balanced'],\n",
    "                'gbc__iterations': [200]}\n",
    "\n",
    "\n",
    "f1_gbc, model_gbc_rs = rs_func(pipeline_gbc, params_gbc)\n",
    "f1_gbc, model_gbc_rs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты испытаний всех моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      F1\n",
       "LogisticRegression 0.745\n",
       "LinearSVC          0.746\n",
       "SGDClassifier      0.711\n",
       "CatBoost           0.737"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_table = pd.DataFrame([ f1_logr, f1_svc, f1_sgd, f1_gbc],\n",
    "                            columns=[ 'F1'],\n",
    "                            index=['LogisticRegression', 'LinearSVC', 'SGDClassifier', 'CatBoost'])\n",
    "results_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат на кросс-валидации показала модель LogisticRegression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование модели\n",
    "Протестируем выбранную модель на ранее отложенной тестовой выборке.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_TEST</th>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           F1\n",
       "LogisticRegression      0.745\n",
       "LinearSVC               0.746\n",
       "SGDClassifier           0.711\n",
       "CatBoost                0.737\n",
       "LogisticRegression_TEST 0.753"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# предсказания с помощью пайплайна с логистической регрессией\n",
    "y_pred = model_logr_rs.predict(X_test)\n",
    "\n",
    "# применим к тестовой выборке, добавим в сводую таблицу результат\n",
    "results_table.loc['LogisticRegression_TEST'] = f1_score(y_test, y_pred)\n",
    "results_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На новых данных модель показывает равнозначный результат. Посмотрим подробнее на матрице ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# построим Confusion Matrix, отображение в долях\n",
    "cm = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap='GnBu')\n",
    "plt.title('Матрица ошибок модели LogisticRegression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель ошибается в предсказании положительного класса (токсичный комментарий) в 27% и более точна в предсказании отрицательного (нетоксичный) 98%.\n",
    "\n",
    "Тест на адекватность - проверим, предсказывает ли наша модель лучше, чем константная.  \n",
    "Воспроизведём модель, которая всегда предсказывает, что комментарий токсичный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_011fd_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >F1</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_011fd_level0_row0\" class=\"row_heading level0 row0\" >LogisticRegression</th>\n",
       "                        <td id=\"T_011fd_row0_col0\" class=\"data row0 col0\" >0.75</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_011fd_level0_row1\" class=\"row_heading level0 row1\" >LinearSVC</th>\n",
       "                        <td id=\"T_011fd_row1_col0\" class=\"data row1 col0\" >0.75</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_011fd_level0_row2\" class=\"row_heading level0 row2\" >SGDClassifier</th>\n",
       "                        <td id=\"T_011fd_row2_col0\" class=\"data row2 col0\" >0.71</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_011fd_level0_row3\" class=\"row_heading level0 row3\" >CatBoost</th>\n",
       "                        <td id=\"T_011fd_row3_col0\" class=\"data row3 col0\" >0.74</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_011fd_level0_row4\" class=\"row_heading level0 row4\" >LogisticRegression_TEST</th>\n",
       "                        <td id=\"T_011fd_row4_col0\" class=\"data row4 col0\" >0.75</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_011fd_level0_row5\" class=\"row_heading level0 row5\" >Dummy</th>\n",
       "                        <td id=\"T_011fd_row5_col0\" class=\"data row5 col0\" >0.18</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd73d581f70>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# воспроизведём случай, что модель всегда предсказывает 1\n",
    "dummy = DummyClassifier(strategy='constant', constant=1)\n",
    "dummy.fit(X_train, y_train)\n",
    "dummy_pred = dummy.predict(X_test)\n",
    "\n",
    "results_table.loc['Dummy'] = f1_score(y_test, dummy.predict(X_test))\n",
    "results_table.style.set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбранная модель LogisticRegression с подобранным набором гиперпараметров прошла финальное испытание:\n",
    "- F1-мера на тестовой выборке равно 0.75\n",
    "- Модель предсказывает лучше, чем случайная"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Итоги\n",
    "Перед была поставлена задача прогнозирования эмоциональной окраски текста комментария — 0 («положительная») или 1 («отрицательная») с целью отправки их на модерацию.\n",
    "\n",
    "Для исследования предоставлен набор данных, содержащий 159 292 текстов с разметкой о токсичности. В распределении целевого признака выявлен дисбаланс классов: всего 10% токсичных комментарив. \n",
    "\n",
    "Для обучения моделей текст предварительно был обработан:\n",
    "- очищен от символов, цифр, стоп-слов\n",
    "- лемматизарован\n",
    "- приведён к векторному представлению слов при помощи алгоритма TF-IDF - выбран один из 4-х рассмотренных вариантов\n",
    "\n",
    "Для поиска лучшего решения протестированы 4 модели: 3 линейные - LogisticRegression, LinearSVC, SGDClassifier, и градиентный бустинг CatBoost. Для устранения влияния дисбаланса классов при обучении использован гиперпараметр class_weight='balanced'.\n",
    "\n",
    "Для оценки качества использована метрика F1-мера. Заданное условие: F1-мера ≥ 0.75 на тестовой выборке.\n",
    "\n",
    "В результате исследования для решения задачи выбрана комбинация с моделью **TF-IDF + LogisticRegression** с подобранным набором гиперпараметров. Заданное условие качества модели достигнуто - F1-мера = 0.75.\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 4205,
    "start_time": "2023-06-14T16:24:34.026Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-14T16:24:38.233Z"
   },
   {
    "duration": 245,
    "start_time": "2023-06-14T16:24:50.445Z"
   },
   {
    "duration": 2518,
    "start_time": "2023-06-14T16:24:54.730Z"
   },
   {
    "duration": 23,
    "start_time": "2023-06-14T16:25:00.255Z"
   },
   {
    "duration": 939,
    "start_time": "2023-06-14T16:25:18.158Z"
   },
   {
    "duration": 13,
    "start_time": "2023-06-14T16:25:19.100Z"
   },
   {
    "duration": 862,
    "start_time": "2023-06-14T16:25:38.277Z"
   },
   {
    "duration": 14,
    "start_time": "2023-06-14T16:25:39.562Z"
   },
   {
    "duration": 864,
    "start_time": "2023-06-14T16:25:45.040Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-14T16:25:45.907Z"
   },
   {
    "duration": 990,
    "start_time": "2023-06-14T16:27:13.738Z"
   },
   {
    "duration": 16,
    "start_time": "2023-06-14T16:27:15.271Z"
   },
   {
    "duration": 1028,
    "start_time": "2023-06-14T16:27:23.627Z"
   },
   {
    "duration": 33,
    "start_time": "2023-06-14T16:27:24.657Z"
   },
   {
    "duration": 210,
    "start_time": "2023-06-14T16:28:36.747Z"
   },
   {
    "duration": 17,
    "start_time": "2023-06-14T16:28:37.084Z"
   },
   {
    "duration": 947,
    "start_time": "2023-06-14T16:28:42.447Z"
   },
   {
    "duration": 13,
    "start_time": "2023-06-14T16:28:43.397Z"
   },
   {
    "duration": 920,
    "start_time": "2023-06-14T16:28:55.096Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-14T16:29:02.304Z"
   },
   {
    "duration": 33,
    "start_time": "2023-06-14T16:29:35.412Z"
   },
   {
    "duration": 11,
    "start_time": "2023-06-14T16:29:35.804Z"
   },
   {
    "duration": 973,
    "start_time": "2023-06-14T16:29:51.757Z"
   },
   {
    "duration": 27,
    "start_time": "2023-06-14T16:29:52.961Z"
   },
   {
    "duration": 955,
    "start_time": "2023-06-14T16:30:00.901Z"
   },
   {
    "duration": 30,
    "start_time": "2023-06-14T16:30:01.866Z"
   },
   {
    "duration": 991,
    "start_time": "2023-06-14T16:30:06.854Z"
   },
   {
    "duration": 21,
    "start_time": "2023-06-14T16:30:07.847Z"
   },
   {
    "duration": 19,
    "start_time": "2023-06-14T16:30:24.662Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-14T16:30:29.501Z"
   },
   {
    "duration": 255,
    "start_time": "2023-06-14T16:30:33.740Z"
   },
   {
    "duration": 212,
    "start_time": "2023-06-14T16:30:38.382Z"
   },
   {
    "duration": 27984,
    "start_time": "2023-06-14T16:36:11.045Z"
   },
   {
    "duration": 854,
    "start_time": "2023-06-14T16:39:23.508Z"
   },
   {
    "duration": 223,
    "start_time": "2023-06-14T16:39:57.795Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-14T16:40:31.226Z"
   },
   {
    "duration": 93233,
    "start_time": "2023-06-14T16:41:49.415Z"
   },
   {
    "duration": 266490,
    "start_time": "2023-06-14T16:43:39.311Z"
   },
   {
    "duration": 68,
    "start_time": "2023-06-14T17:08:30.035Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-14T17:08:30.444Z"
   },
   {
    "duration": 8112,
    "start_time": "2023-06-14T17:08:33.409Z"
   },
   {
    "duration": 3304,
    "start_time": "2023-06-14T17:08:41.523Z"
   },
   {
    "duration": 10,
    "start_time": "2023-06-14T17:08:44.830Z"
   },
   {
    "duration": 3442,
    "start_time": "2023-06-14T17:08:44.843Z"
   },
   {
    "duration": 5719,
    "start_time": "2023-06-14T17:09:16.296Z"
   },
   {
    "duration": 197,
    "start_time": "2023-06-14T17:09:23.185Z"
   },
   {
    "duration": 261091,
    "start_time": "2023-06-14T17:09:25.938Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-14T17:16:04.698Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-14T17:16:06.215Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-14T17:16:08.092Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-14T17:16:10.085Z"
   },
   {
    "duration": 62,
    "start_time": "2023-06-14T17:16:20.911Z"
   },
   {
    "duration": 71,
    "start_time": "2023-06-14T17:16:26.536Z"
   },
   {
    "duration": 42,
    "start_time": "2023-06-14T17:16:41.034Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-14T17:17:21.661Z"
   },
   {
    "duration": 43,
    "start_time": "2023-06-14T17:17:22.604Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-14T17:18:02.880Z"
   },
   {
    "duration": 60014,
    "start_time": "2023-06-14T17:18:28.922Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-14T17:19:28.938Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-14T17:19:28.947Z"
   },
   {
    "duration": 52,
    "start_time": "2023-06-14T17:19:28.956Z"
   },
   {
    "duration": 251229,
    "start_time": "2023-06-14T17:19:37.217Z"
   },
   {
    "duration": 55,
    "start_time": "2023-06-14T17:23:48.447Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-14T17:23:51.149Z"
   },
   {
    "duration": 10,
    "start_time": "2023-06-14T17:23:52.685Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-14T17:23:58.631Z"
   },
   {
    "duration": 58,
    "start_time": "2023-06-14T17:23:59.843Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-14T17:24:14.422Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-14T17:24:38.510Z"
   },
   {
    "duration": 26,
    "start_time": "2023-06-14T17:24:45.754Z"
   },
   {
    "duration": 83,
    "start_time": "2023-06-14T17:27:21.681Z"
   },
   {
    "duration": 498,
    "start_time": "2023-06-14T17:27:40.993Z"
   },
   {
    "duration": 57,
    "start_time": "2023-06-14T17:30:01.849Z"
   },
   {
    "duration": 4473,
    "start_time": "2023-06-14T17:30:30.141Z"
   },
   {
    "duration": 2774,
    "start_time": "2023-06-14T17:30:34.616Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-14T17:30:37.392Z"
   },
   {
    "duration": 2429,
    "start_time": "2023-06-14T17:30:37.401Z"
   },
   {
    "duration": 253468,
    "start_time": "2023-06-14T17:30:45.484Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-14T17:34:58.964Z"
   },
   {
    "duration": 23,
    "start_time": "2023-06-14T17:34:58.978Z"
   },
   {
    "duration": 25,
    "start_time": "2023-06-14T17:34:59.003Z"
   },
   {
    "duration": 20702,
    "start_time": "2023-06-14T17:34:59.030Z"
   },
   {
    "duration": 604,
    "start_time": "2023-06-14T17:35:19.734Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-14T17:35:20.340Z"
   },
   {
    "duration": 53,
    "start_time": "2023-06-14T17:38:16.253Z"
   },
   {
    "duration": 61,
    "start_time": "2023-06-14T17:40:00.516Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-14T17:40:25.188Z"
   },
   {
    "duration": 43,
    "start_time": "2023-06-14T17:40:27.881Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-14T17:42:00.282Z"
   },
   {
    "duration": 38,
    "start_time": "2023-06-14T17:48:10.447Z"
   },
   {
    "duration": 62,
    "start_time": "2023-06-14T17:48:28.585Z"
   },
   {
    "duration": 47928,
    "start_time": "2023-06-14T17:49:11.876Z"
   },
   {
    "duration": 19,
    "start_time": "2023-06-14T17:50:14.932Z"
   },
   {
    "duration": 18,
    "start_time": "2023-06-14T17:54:24.186Z"
   },
   {
    "duration": 18,
    "start_time": "2023-06-14T17:55:10.409Z"
   },
   {
    "duration": 166317,
    "start_time": "2023-06-14T17:55:57.879Z"
   },
   {
    "duration": 255345,
    "start_time": "2023-06-14T17:58:50.420Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-14T18:03:46.784Z"
   },
   {
    "duration": 52,
    "start_time": "2023-06-14T18:03:59.583Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-14T18:04:05.784Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-14T18:04:06.464Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-14T18:04:06.903Z"
   },
   {
    "duration": 24,
    "start_time": "2023-06-14T18:04:12.674Z"
   },
   {
    "duration": 165,
    "start_time": "2023-06-14T18:38:11.265Z"
   },
   {
    "duration": 2406,
    "start_time": "2023-06-14T18:38:11.871Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-14T18:38:14.280Z"
   },
   {
    "duration": 1682,
    "start_time": "2023-06-14T18:38:15.105Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-14T18:38:30.060Z"
   },
   {
    "duration": 68,
    "start_time": "2023-06-14T18:38:59.212Z"
   },
   {
    "duration": 65,
    "start_time": "2023-06-14T18:39:06.811Z"
   },
   {
    "duration": 4578,
    "start_time": "2023-06-14T18:39:40.232Z"
   },
   {
    "duration": 2965,
    "start_time": "2023-06-14T18:39:44.816Z"
   },
   {
    "duration": 16,
    "start_time": "2023-06-14T18:39:47.783Z"
   },
   {
    "duration": 244850,
    "start_time": "2023-06-14T18:39:47.804Z"
   },
   {
    "duration": 1637,
    "start_time": "2023-06-14T18:43:52.656Z"
   },
   {
    "duration": 4648,
    "start_time": "2023-06-14T19:43:24.720Z"
   },
   {
    "duration": 2447,
    "start_time": "2023-06-14T19:43:29.371Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-14T19:43:31.820Z"
   },
   {
    "duration": 18652,
    "start_time": "2023-06-14T19:43:39.147Z"
   },
   {
    "duration": 76,
    "start_time": "2023-06-14T19:43:57.802Z"
   },
   {
    "duration": 19,
    "start_time": "2023-06-14T19:43:57.880Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-14T19:43:57.901Z"
   },
   {
    "duration": 17,
    "start_time": "2023-06-14T19:44:41.549Z"
   },
   {
    "duration": 16,
    "start_time": "2023-06-14T19:44:56.052Z"
   },
   {
    "duration": 14,
    "start_time": "2023-06-14T19:45:04.451Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-14T19:45:05.939Z"
   },
   {
    "duration": 70517,
    "start_time": "2023-06-14T19:45:08.084Z"
   },
   {
    "duration": 458,
    "start_time": "2023-06-14T19:46:18.603Z"
   },
   {
    "duration": 12433,
    "start_time": "2023-06-14T19:46:19.064Z"
   },
   {
    "duration": 1752,
    "start_time": "2023-06-14T19:46:31.499Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-14T19:46:33.253Z"
   },
   {
    "duration": 26,
    "start_time": "2023-06-14T19:46:33.258Z"
   },
   {
    "duration": 2972,
    "start_time": "2023-06-15T06:51:39.424Z"
   },
   {
    "duration": 3256,
    "start_time": "2023-06-15T06:51:42.399Z"
   },
   {
    "duration": 14,
    "start_time": "2023-06-15T06:51:45.657Z"
   },
   {
    "duration": 31,
    "start_time": "2023-06-15T06:51:45.674Z"
   },
   {
    "duration": 11,
    "start_time": "2023-06-15T06:51:45.706Z"
   },
   {
    "duration": 268,
    "start_time": "2023-06-15T06:51:45.719Z"
   },
   {
    "duration": 1724,
    "start_time": "2023-06-15T06:52:30.394Z"
   },
   {
    "duration": 75296,
    "start_time": "2023-06-15T06:52:36.025Z"
   },
   {
    "duration": 478,
    "start_time": "2023-06-15T06:54:43.351Z"
   },
   {
    "duration": 3030,
    "start_time": "2023-06-15T06:56:40.611Z"
   },
   {
    "duration": 213,
    "start_time": "2023-06-15T06:59:35.052Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-15T06:59:39.151Z"
   },
   {
    "duration": 1884,
    "start_time": "2023-06-15T06:59:39.159Z"
   },
   {
    "duration": 2505,
    "start_time": "2023-06-15T06:59:41.046Z"
   },
   {
    "duration": 15,
    "start_time": "2023-06-15T06:59:43.554Z"
   },
   {
    "duration": 37,
    "start_time": "2023-06-15T06:59:43.574Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-15T06:59:43.614Z"
   },
   {
    "duration": 216,
    "start_time": "2023-06-15T06:59:43.624Z"
   },
   {
    "duration": 15,
    "start_time": "2023-06-15T06:59:47.168Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-15T06:59:47.640Z"
   },
   {
    "duration": 23,
    "start_time": "2023-06-15T06:59:59.108Z"
   },
   {
    "duration": 10,
    "start_time": "2023-06-15T07:00:03.555Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-15T07:00:04.567Z"
   },
   {
    "duration": 3066,
    "start_time": "2023-06-15T07:00:06.899Z"
   },
   {
    "duration": 16,
    "start_time": "2023-06-15T07:00:26.231Z"
   },
   {
    "duration": 3837,
    "start_time": "2023-06-15T07:00:29.721Z"
   },
   {
    "duration": 27,
    "start_time": "2023-06-15T07:01:09.804Z"
   },
   {
    "duration": 3197,
    "start_time": "2023-06-15T07:01:12.665Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-15T07:08:36.894Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-15T07:08:45.404Z"
   },
   {
    "duration": 2829,
    "start_time": "2023-06-15T07:08:55.535Z"
   },
   {
    "duration": 77201,
    "start_time": "2023-06-15T07:09:19.160Z"
   },
   {
    "duration": 2382,
    "start_time": "2023-07-03T21:18:58.203Z"
   },
   {
    "duration": 2721,
    "start_time": "2023-07-03T21:19:00.587Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-03T21:19:03.310Z"
   },
   {
    "duration": 18,
    "start_time": "2023-07-03T21:19:03.315Z"
   },
   {
    "duration": 2584,
    "start_time": "2023-07-03T21:19:03.334Z"
   },
   {
    "duration": 19,
    "start_time": "2023-07-03T21:19:05.921Z"
   },
   {
    "duration": 38,
    "start_time": "2023-07-03T21:19:10.064Z"
   },
   {
    "duration": 245,
    "start_time": "2023-07-03T21:19:10.298Z"
   },
   {
    "duration": 7,
    "start_time": "2023-07-03T21:19:12.069Z"
   },
   {
    "duration": 82,
    "start_time": "2023-07-03T21:19:20.740Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-03T21:19:32.570Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-03T21:19:33.048Z"
   },
   {
    "duration": 3009,
    "start_time": "2023-07-03T21:20:03.378Z"
   },
   {
    "duration": 853,
    "start_time": "2023-07-03T21:23:32.936Z"
   },
   {
    "duration": 303824,
    "start_time": "2023-07-03T21:23:44.543Z"
   },
   {
    "duration": 159228,
    "start_time": "2023-07-03T21:30:05.141Z"
   },
   {
    "duration": 132,
    "start_time": "2023-07-03T21:33:41.785Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-03T21:33:52.031Z"
   },
   {
    "duration": 1145,
    "start_time": "2023-07-03T21:33:59.636Z"
   },
   {
    "duration": 7,
    "start_time": "2023-07-03T21:34:48.493Z"
   },
   {
    "duration": 1126,
    "start_time": "2023-07-03T21:34:50.640Z"
   },
   {
    "duration": 8,
    "start_time": "2023-07-03T21:38:47.994Z"
   },
   {
    "duration": 1212,
    "start_time": "2023-07-03T21:38:48.502Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-03T21:39:53.878Z"
   },
   {
    "duration": 1256,
    "start_time": "2023-07-03T21:39:54.793Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-03T21:40:35.828Z"
   },
   {
    "duration": 1165,
    "start_time": "2023-07-03T21:40:37.984Z"
   },
   {
    "duration": 160061,
    "start_time": "2023-07-03T21:41:10.321Z"
   },
   {
    "duration": 9,
    "start_time": "2023-07-03T21:43:56.807Z"
   },
   {
    "duration": 1898,
    "start_time": "2023-07-03T21:44:01.476Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-03T21:46:38.177Z"
   },
   {
    "duration": 2501,
    "start_time": "2023-07-03T21:46:38.833Z"
   },
   {
    "duration": 8,
    "start_time": "2023-07-03T21:46:52.922Z"
   },
   {
    "duration": 2522,
    "start_time": "2023-07-03T21:46:53.107Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-03T21:49:11.631Z"
   },
   {
    "duration": 1644,
    "start_time": "2023-07-03T21:49:12.558Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-03T21:49:32.290Z"
   },
   {
    "duration": 1761,
    "start_time": "2023-07-03T21:49:32.623Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-03T21:49:55.625Z"
   },
   {
    "duration": 1805,
    "start_time": "2023-07-03T21:49:55.882Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-03T21:50:47.908Z"
   },
   {
    "duration": 87475,
    "start_time": "2023-07-03T21:50:48.173Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-03T21:53:05.799Z"
   },
   {
    "duration": 804,
    "start_time": "2023-07-03T21:53:06.109Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-03T21:53:30.728Z"
   },
   {
    "duration": 15064,
    "start_time": "2023-07-03T21:53:30.928Z"
   },
   {
    "duration": 11,
    "start_time": "2023-07-04T07:19:30.429Z"
   },
   {
    "duration": 53,
    "start_time": "2023-07-04T07:19:44.795Z"
   },
   {
    "duration": 6770,
    "start_time": "2023-07-04T07:19:58.085Z"
   },
   {
    "duration": 362,
    "start_time": "2023-07-04T07:20:07.394Z"
   },
   {
    "duration": 582,
    "start_time": "2023-07-04T07:20:21.379Z"
   },
   {
    "duration": 24,
    "start_time": "2023-07-04T07:20:34.613Z"
   },
   {
    "duration": 2570,
    "start_time": "2023-07-04T07:20:46.426Z"
   },
   {
    "duration": 4866,
    "start_time": "2023-07-04T07:20:48.998Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-04T07:21:00.655Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-04T07:21:00.851Z"
   },
   {
    "duration": 3339,
    "start_time": "2023-07-04T07:21:01.258Z"
   },
   {
    "duration": 21,
    "start_time": "2023-07-04T07:21:04.599Z"
   },
   {
    "duration": 35,
    "start_time": "2023-07-04T07:21:11.504Z"
   },
   {
    "duration": 236,
    "start_time": "2023-07-04T07:21:11.707Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-04T07:21:12.502Z"
   },
   {
    "duration": 77,
    "start_time": "2023-07-04T07:21:13.051Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-04T07:21:16.189Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-04T07:21:16.356Z"
   },
   {
    "duration": 5357,
    "start_time": "2023-07-04T07:21:26.395Z"
   },
   {
    "duration": 3868,
    "start_time": "2023-07-04T07:21:36.675Z"
   },
   {
    "duration": 194162,
    "start_time": "2023-07-04T07:21:44.086Z"
   },
   {
    "duration": 78,
    "start_time": "2023-07-04T07:24:58.250Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-04T07:24:58.330Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-04T07:25:15.573Z"
   },
   {
    "duration": 47754,
    "start_time": "2023-07-04T07:25:16.041Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-04T07:26:21.493Z"
   },
   {
    "duration": 94600,
    "start_time": "2023-07-04T07:26:22.660Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-04T07:28:39.334Z"
   },
   {
    "duration": 190351,
    "start_time": "2023-07-04T07:28:39.647Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-04T07:32:18.970Z"
   },
   {
    "duration": 1805,
    "start_time": "2023-07-04T07:32:19.288Z"
   },
   {
    "duration": 7,
    "start_time": "2023-07-04T07:32:39.661Z"
   },
   {
    "duration": 1638,
    "start_time": "2023-07-04T07:32:39.919Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-04T07:32:54.551Z"
   },
   {
    "duration": 1498,
    "start_time": "2023-07-04T07:32:54.762Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-04T07:33:11.827Z"
   },
   {
    "duration": 45479,
    "start_time": "2023-07-04T07:33:11.989Z"
   },
   {
    "duration": 19810,
    "start_time": "2023-07-04T07:34:09.602Z"
   },
   {
    "duration": 45,
    "start_time": "2023-07-04T07:42:46.633Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-04T07:43:22.413Z"
   },
   {
    "duration": 5407,
    "start_time": "2023-07-04T07:43:33.591Z"
   },
   {
    "duration": 212,
    "start_time": "2023-07-04T07:44:02.107Z"
   },
   {
    "duration": 26,
    "start_time": "2023-07-04T07:44:02.323Z"
   },
   {
    "duration": 19827,
    "start_time": "2023-07-04T07:44:03.204Z"
   },
   {
    "duration": 7,
    "start_time": "2023-07-04T07:44:40.513Z"
   },
   {
    "duration": 4149,
    "start_time": "2023-07-04T07:44:40.703Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-04T07:45:37.874Z"
   },
   {
    "duration": 1855,
    "start_time": "2023-07-04T07:45:39.633Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-04T07:46:11.142Z"
   },
   {
    "duration": 1767,
    "start_time": "2023-07-04T07:46:11.642Z"
   },
   {
    "duration": 83467,
    "start_time": "2023-07-04T07:47:12.983Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-04T07:49:10.612Z"
   },
   {
    "duration": 1597,
    "start_time": "2023-07-04T07:49:13.335Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-04T07:51:16.734Z"
   },
   {
    "duration": 1223,
    "start_time": "2023-07-04T07:51:21.019Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-04T07:55:32.104Z"
   },
   {
    "duration": 2814,
    "start_time": "2023-07-04T07:55:35.714Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-04T07:56:22.362Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-04T07:56:22.604Z"
   },
   {
    "duration": 2516,
    "start_time": "2023-07-04T07:56:23.299Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-04T07:57:03.939Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-04T07:57:04.133Z"
   },
   {
    "duration": 2622,
    "start_time": "2023-07-04T07:57:05.826Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-04T07:57:38.937Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-04T07:57:39.466Z"
   },
   {
    "duration": 2887,
    "start_time": "2023-07-04T07:57:39.876Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-04T07:59:50.828Z"
   },
   {
    "duration": 2588,
    "start_time": "2023-07-04T08:00:58.773Z"
   },
   {
    "duration": 4671,
    "start_time": "2023-07-04T08:01:01.364Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-04T08:01:06.036Z"
   },
   {
    "duration": 15,
    "start_time": "2023-07-04T08:01:06.045Z"
   },
   {
    "duration": 788,
    "start_time": "2023-07-04T08:01:06.062Z"
   },
   {
    "duration": 17,
    "start_time": "2023-07-04T08:01:06.852Z"
   },
   {
    "duration": 33,
    "start_time": "2023-07-04T08:01:11.306Z"
   },
   {
    "duration": 237,
    "start_time": "2023-07-04T08:01:12.001Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-04T08:01:12.488Z"
   },
   {
    "duration": 64,
    "start_time": "2023-07-04T08:01:14.440Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-04T08:01:18.591Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-04T08:01:19.733Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-04T08:01:21.476Z"
   },
   {
    "duration": 370,
    "start_time": "2023-07-04T08:13:08.779Z"
   },
   {
    "duration": 624,
    "start_time": "2023-07-04T08:13:16.367Z"
   },
   {
    "duration": 13656,
    "start_time": "2023-07-04T08:13:22.652Z"
   },
   {
    "duration": 4402,
    "start_time": "2023-07-04T08:15:07.160Z"
   },
   {
    "duration": 9149,
    "start_time": "2023-07-04T08:15:15.139Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-04T08:17:07.876Z"
   },
   {
    "duration": 101852,
    "start_time": "2023-07-04T08:17:54.284Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-04T08:19:36.139Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-04T08:19:49.878Z"
   },
   {
    "duration": 172316,
    "start_time": "2023-07-04T08:38:20.713Z"
   },
   {
    "duration": 23,
    "start_time": "2023-07-04T08:41:20.493Z"
   },
   {
    "duration": 6000,
    "start_time": "2023-07-04T08:41:47.314Z"
   },
   {
    "duration": 176475,
    "start_time": "2023-07-04T08:42:39.056Z"
   },
   {
    "duration": 380,
    "start_time": "2023-07-04T08:45:50.134Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-04T08:45:58.771Z"
   },
   {
    "duration": 93810,
    "start_time": "2023-07-04T08:46:02.713Z"
   },
   {
    "duration": 41,
    "start_time": "2023-07-04T08:48:44.112Z"
   },
   {
    "duration": 36,
    "start_time": "2023-07-04T08:48:44.996Z"
   },
   {
    "duration": 204,
    "start_time": "2023-07-04T08:48:45.173Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-04T08:48:45.531Z"
   },
   {
    "duration": 69,
    "start_time": "2023-07-04T08:48:46.568Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-04T08:48:52.600Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-04T08:48:52.823Z"
   },
   {
    "duration": 32748,
    "start_time": "2023-07-04T08:48:54.554Z"
   },
   {
    "duration": 93975,
    "start_time": "2023-07-04T08:49:33.248Z"
   },
   {
    "duration": 325,
    "start_time": "2023-07-04T09:14:32.495Z"
   },
   {
    "duration": 43,
    "start_time": "2023-07-04T09:23:48.013Z"
   },
   {
    "duration": 31,
    "start_time": "2023-07-04T09:35:04.106Z"
   },
   {
    "duration": 22,
    "start_time": "2023-07-04T09:35:18.663Z"
   },
   {
    "duration": 12,
    "start_time": "2023-07-04T09:35:27.454Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-04T09:35:27.620Z"
   },
   {
    "duration": 564201,
    "start_time": "2023-07-04T09:35:35.343Z"
   },
   {
    "duration": 3956,
    "start_time": "2023-07-04T09:45:37.228Z"
   },
   {
    "duration": 107906,
    "start_time": "2023-07-04T09:45:46.207Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-04T09:48:06.741Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-04T09:48:18.815Z"
   },
   {
    "duration": 2425,
    "start_time": "2023-07-05T16:19:40.637Z"
   },
   {
    "duration": 5315,
    "start_time": "2023-07-05T16:19:43.064Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-05T16:19:48.380Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-05T16:19:48.387Z"
   },
   {
    "duration": 3271,
    "start_time": "2023-07-05T16:19:48.394Z"
   },
   {
    "duration": 17,
    "start_time": "2023-07-05T16:19:51.667Z"
   },
   {
    "duration": 30,
    "start_time": "2023-07-05T16:20:02.706Z"
   },
   {
    "duration": 203,
    "start_time": "2023-07-05T16:20:02.982Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-05T16:20:06.693Z"
   },
   {
    "duration": 61,
    "start_time": "2023-07-05T16:20:09.282Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-05T16:20:48.595Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-05T16:20:49.148Z"
   },
   {
    "duration": 84601,
    "start_time": "2023-07-05T16:20:52.580Z"
   },
   {
    "duration": 11,
    "start_time": "2023-07-05T16:22:51.970Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-05T16:22:52.193Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-05T16:23:32.155Z"
   },
   {
    "duration": 2,
    "start_time": "2023-07-05T16:23:32.315Z"
   },
   {
    "duration": 108199,
    "start_time": "2023-07-05T16:25:32.371Z"
   },
   {
    "duration": 347503,
    "start_time": "2023-07-05T16:27:23.184Z"
   },
   {
    "duration": 76235,
    "start_time": "2023-07-05T16:36:57.890Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-05T16:38:14.127Z"
   },
   {
    "duration": 22,
    "start_time": "2023-07-05T16:38:16.418Z"
   },
   {
    "duration": 28506,
    "start_time": "2023-07-05T16:38:48.889Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-05T16:39:52.030Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-05T16:39:58.064Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-05T16:40:12.546Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-05T16:40:18.964Z"
   },
   {
    "duration": 69304,
    "start_time": "2023-07-05T16:41:51.194Z"
   },
   {
    "duration": 30420,
    "start_time": "2023-07-05T16:44:32.382Z"
   },
   {
    "duration": 44,
    "start_time": "2023-07-05T16:45:11.159Z"
   },
   {
    "duration": 28470,
    "start_time": "2023-07-05T16:45:52.726Z"
   },
   {
    "duration": 211671,
    "start_time": "2023-07-05T16:47:07.506Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-05T16:50:54.352Z"
   },
   {
    "duration": 75,
    "start_time": "2023-07-05T16:52:16.202Z"
   },
   {
    "duration": 28911,
    "start_time": "2023-07-05T16:52:33.258Z"
   },
   {
    "duration": 11,
    "start_time": "2023-07-05T16:53:12.142Z"
   },
   {
    "duration": 28601,
    "start_time": "2023-07-05T16:53:58.296Z"
   },
   {
    "duration": 7,
    "start_time": "2023-07-05T16:54:48.687Z"
   },
   {
    "duration": 27,
    "start_time": "2023-07-05T16:55:22.671Z"
   },
   {
    "duration": 18235,
    "start_time": "2023-07-05T16:55:35.444Z"
   },
   {
    "duration": 8,
    "start_time": "2023-07-05T16:56:17.524Z"
   },
   {
    "duration": 28363,
    "start_time": "2023-07-05T16:56:54.642Z"
   },
   {
    "duration": 7,
    "start_time": "2023-07-05T16:57:42.164Z"
   },
   {
    "duration": 626507,
    "start_time": "2023-07-05T16:58:53.079Z"
   },
   {
    "duration": 20,
    "start_time": "2023-07-05T17:09:30.597Z"
   },
   {
    "duration": 9,
    "start_time": "2023-07-05T17:09:46.607Z"
   },
   {
    "duration": 346679,
    "start_time": "2023-07-05T17:09:59.392Z"
   },
   {
    "duration": 214610,
    "start_time": "2023-07-05T17:16:31.968Z"
   },
   {
    "duration": 626611,
    "start_time": "2023-07-05T17:23:26.571Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-05T17:33:53.184Z"
   },
   {
    "duration": 31,
    "start_time": "2023-07-05T17:33:53.188Z"
   },
   {
    "duration": 62752,
    "start_time": "2023-07-05T17:33:53.221Z"
   },
   {
    "duration": 14697,
    "start_time": "2023-07-05T17:34:55.975Z"
   },
   {
    "duration": 8525,
    "start_time": "2023-07-05T17:35:10.674Z"
   },
   {
    "duration": 4020,
    "start_time": "2023-07-05T17:35:19.200Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-05T17:35:23.222Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-05T17:35:23.223Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-05T17:35:23.225Z"
   },
   {
    "duration": 7,
    "start_time": "2023-07-05T17:37:21.260Z"
   },
   {
    "duration": 9,
    "start_time": "2023-07-05T17:37:37.515Z"
   },
   {
    "duration": 7,
    "start_time": "2023-07-05T17:37:47.283Z"
   },
   {
    "duration": 18,
    "start_time": "2023-07-05T17:38:17.751Z"
   },
   {
    "duration": 23,
    "start_time": "2023-07-05T17:38:27.060Z"
   },
   {
    "duration": 445,
    "start_time": "2023-07-05T17:38:39.071Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-05T17:38:51.571Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-05T17:39:35.612Z"
   },
   {
    "duration": 2751,
    "start_time": "2023-07-05T17:40:28.122Z"
   },
   {
    "duration": 2863,
    "start_time": "2023-07-05T17:40:43.870Z"
   },
   {
    "duration": 71304,
    "start_time": "2023-07-05T17:41:25.699Z"
   },
   {
    "duration": 7744,
    "start_time": "2023-07-05T17:43:20.062Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-05T17:44:01.304Z"
   },
   {
    "duration": 171519,
    "start_time": "2023-07-05T17:44:04.760Z"
   },
   {
    "duration": 90,
    "start_time": "2023-07-05T17:46:56.282Z"
   },
   {
    "duration": 177,
    "start_time": "2023-07-05T17:46:56.374Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-05T17:46:56.553Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-05T17:46:56.555Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-05T17:46:56.557Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-05T17:46:56.558Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-05T17:46:56.559Z"
   },
   {
    "duration": 24,
    "start_time": "2023-07-05T17:48:54.164Z"
   },
   {
    "duration": 381499,
    "start_time": "2023-07-05T17:49:00.079Z"
   },
   {
    "duration": 18,
    "start_time": "2023-07-05T17:55:26.816Z"
   },
   {
    "duration": 18,
    "start_time": "2023-07-05T17:55:46.430Z"
   },
   {
    "duration": 7,
    "start_time": "2023-07-05T17:56:16.659Z"
   },
   {
    "duration": 3074,
    "start_time": "2023-07-05T17:56:26.600Z"
   },
   {
    "duration": 2574,
    "start_time": "2023-07-05T17:56:33.653Z"
   },
   {
    "duration": 2021,
    "start_time": "2023-07-05T17:56:45.912Z"
   },
   {
    "duration": 25,
    "start_time": "2023-07-05T17:56:54.848Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
